{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3852ce9",
   "metadata": {},
   "source": [
    "# 法律 RAG Notebook 工作流\n",
    "此 Notebook 示範如何以模組化方式載入 `rag_system` Workflow，替代舊有 CLI。\n",
    "1. 載入環境變數並建立 `RAGConfig`。\n",
    "2. 透過 `rag_system.workflow` 建立 LLM 與 LangGraph Workflow。\n",
    "3. 以程式方式執行查詢並顯示答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd826e0c-277e-4787-abf3-86e82cba376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure project root is in python path\n",
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith(\"notebooks\"):\n",
    "    sys.path.append(os.path.abspath(\"..\"))\n",
    "elif \"rag_system\" not in os.listdir(current_dir):\n",
    "    # Fallback try\n",
    "    sys.path.append(os.path.abspath(\".\"))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from rag_system.config import RAGConfig\n",
    "from rag_system.workflow import create_llm, create_rag_workflow, run_query\n",
    "\n",
    "load_dotenv()\n",
    "config = RAGConfig.from_env()\n",
    "config.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b70cbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/rag_system/common.py:76: UserWarning: SSL verification is disabled. This is insecure and should only be used for development.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x70b2aa4051d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = create_llm(config)\n",
    "workflow = create_rag_workflow(config, llm=llm, use_hierarchical=True)  # 開啟階層式\n",
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c5263df-18ce-4603-b9f9-30f8b30336eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_system.common import set_quiet_mode\n",
    "\n",
    "set_quiet_mode(False)  # 開啟日誌\n",
    "# set_quiet_mode(True)  # 再次關閉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc6ef43-2360-48bc-8dca-025d50bea60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 00:56:01,086 - INFO - rag_system.common - Using hierarchical retrieval system\n",
      "/home/jovyan/work/rag_system/common.py:76: UserWarning: SSL verification is disabled. This is insecure and should only be used for development.\n",
      "  warnings.warn(\n",
      "2025-12-03 00:56:01,098 - INFO - rag_system.common - Running workflow for question: 陸海空軍懲罰法第7條\n",
      "2025-12-03 00:56:01,099 - INFO - rag_system.common - --- GENERAL AGENT NODE ---\n",
      "2025-12-03 00:56:01,643 - INFO - httpx - HTTP Request: POST http://172.16.120.67:7000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-03 00:56:01,648 - INFO - rag_system.common - Routing legal query: '陸海空軍懲罰法第7條'\n",
      "2025-12-03 00:56:01,657 - INFO - rag_system.common - Found collections with stats: [{'name': '陸海空軍懲罰法', 'doc_count': 86}, {'name': '軍人權益事件處理法', 'doc_count': 85}, {'name': '軍人權益事件處理法-checkpoint', 'doc_count': 85}, {'name': 'test_manual', 'doc_count': 2}]\n",
      "2025-12-03 00:56:02,009 - INFO - httpx - HTTP Request: POST http://172.16.120.67:7000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-03 00:56:02,010 - INFO - rag_system.common - Router selected collection: '陸海空軍懲罰法'\n",
      "2025-12-03 00:56:02,418 - INFO - httpx - HTTP Request: POST http://172.16.120.67:7000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-03 00:56:02,419 - INFO - rag_system.common - ⚠️ Model stopped after routing. Forcing retrieval step manually.\n",
      "2025-12-03 00:56:02,420 - INFO - rag_system.common - Invoking retrieve_hierarchical with collection='陸海空軍懲罰法'\n",
      "2025-12-03 00:56:02,420 - INFO - rag_system.common - Refined manual query: '陸海空軍懲罰法第7條' -> '第7條'\n",
      "2025-12-03 00:56:02,420 - INFO - rag_system.common - Hierarchical retrieval: query='第7條', collection='陸海空軍懲罰法'\n",
      "2025-12-03 00:56:02,421 - INFO - rag_system.common - Executing hierarchical retrieval with direct strategy\n",
      "2025-12-03 00:56:02,421 - INFO - rag_system.common - Direct retrieval for query: '第7條...'\n",
      "2025-12-03 00:56:02,421 - INFO - rag_system.common - Embedding 1 documents in batches of 8...\n",
      "2025-12-03 00:56:02,422 - INFO - rag_system.common - Processing batch 1/1\n",
      "2025-12-03 00:56:02,422 - INFO - rag_system.common - Sending 1 texts to https://172.16.120.67/v1/embeddings\n",
      "2025-12-03 00:57:02,461 - INFO - httpx - HTTP Request: POST https://172.16.120.67/v1/embeddings \"HTTP/1.1 504 Gateway Time-out\"\n",
      "2025-12-03 00:57:02,462 - ERROR - rag_system.common - Batch failed with status 504: <html>\n",
      "<head><title>504 Gateway Time-out</title></head>\n",
      "<body>\n",
      "<center><h1>504 Gateway Time-out</h1></center>\n",
      "<hr><center>nginx/1.28.0</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "2025-12-03 00:57:02,462 - ERROR - rag_system.common - Error generating embedding: Server error '504 Gateway Time-out' for url 'https://172.16.120.67/v1/embeddings'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/504\n",
      "2025-12-03 00:57:02,462 - INFO - rag_system.common - Error in hierarchical retrieval: Server error '504 Gateway Time-out' for url 'https://172.16.120.67/v1/embeddings'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/504\n",
      "2025-12-03 00:57:02,463 - INFO - rag_system.common - Re-invoking LLM to process manual retrieval results...\n",
      "2025-12-03 00:57:06,800 - INFO - httpx - HTTP Request: POST http://172.16.120.67:7000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**問題答案**  \n",
      "目前無法取得《陸海空軍懲罰法》第7條的具體內容，因為在嘗試檢索時發生了伺服器錯誤，導致無法取得該條文的文字。  \n",
      "\n",
      "**具體條文**  \n",
      "- 無法取得任何具體條文內容。  \n",
      "\n",
      "**結論**  \n",
      "由於檢索失敗，無法提供《陸海空軍懲罰法》第7條的具體條文。若需查閱該條文，建議直接參考官方公布的法規文本或使用其他可靠的法律資料庫。  \n",
      "\n",
      "**參考資料**  \n",
      "- 來源: 《陸海空軍懲罰法》 (無法取得具體條文)\n"
     ]
    }
   ],
   "source": [
    "result_state = run_query(  \"陸海空軍懲罰法第7條\",\n",
    "  config,\n",
    "  llm=llm,\n",
    "  use_hierarchical=True\n",
    ")\n",
    "print(result_state[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5cc180f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 00:57:06,804 - INFO - rag_system.common - Using hierarchical retrieval system\n",
      "/home/jovyan/work/rag_system/common.py:76: UserWarning: SSL verification is disabled. This is insecure and should only be used for development.\n",
      "  warnings.warn(\n",
      "2025-12-03 00:57:06,817 - INFO - rag_system.common - Running workflow for question: 懲罰法適用對象\n",
      "2025-12-03 00:57:06,817 - INFO - rag_system.common - --- GENERAL AGENT NODE ---\n",
      "2025-12-03 00:57:07,275 - INFO - httpx - HTTP Request: POST http://172.16.120.67:7000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-03 00:57:07,277 - INFO - rag_system.common - Routing legal query: '懲罰法適用對象'\n",
      "2025-12-03 00:57:07,285 - INFO - rag_system.common - Found collections with stats: [{'name': '陸海空軍懲罰法', 'doc_count': 86}, {'name': '軍人權益事件處理法', 'doc_count': 85}, {'name': '軍人權益事件處理法-checkpoint', 'doc_count': 85}, {'name': 'test_manual', 'doc_count': 2}]\n",
      "2025-12-03 00:57:07,785 - INFO - httpx - HTTP Request: POST http://172.16.120.67:7000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-03 00:57:07,785 - INFO - rag_system.common - Router selected collection: '陸海空軍懲罰法'\n",
      "2025-12-03 00:57:08,144 - INFO - httpx - HTTP Request: POST http://172.16.120.67:7000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-12-03 00:57:08,145 - INFO - rag_system.common - ⚠️ Model stopped after routing. Forcing retrieval step manually.\n",
      "2025-12-03 00:57:08,145 - INFO - rag_system.common - Invoking retrieve_hierarchical with collection='陸海空軍懲罰法'\n",
      "2025-12-03 00:57:08,145 - INFO - rag_system.common - Refined manual query: '懲罰法適用對象' -> '懲罰法適用對象'\n",
      "2025-12-03 00:57:08,146 - INFO - rag_system.common - Hierarchical retrieval: query='懲罰法適用對象', collection='陸海空軍懲罰法'\n",
      "2025-12-03 00:57:08,146 - INFO - rag_system.common - Executing hierarchical retrieval with direct strategy\n",
      "2025-12-03 00:57:08,146 - INFO - rag_system.common - Direct retrieval for query: '懲罰法適用對象...'\n",
      "2025-12-03 00:57:08,146 - INFO - rag_system.common - Embedding 1 documents in batches of 8...\n",
      "2025-12-03 00:57:08,146 - INFO - rag_system.common - Processing batch 1/1\n",
      "2025-12-03 00:57:08,146 - INFO - rag_system.common - Sending 1 texts to https://172.16.120.67/v1/embeddings\n",
      "2025-12-03 00:57:48,753 - ERROR - rag_system.common - Batch failed due to request error: Server disconnected without sending a response.\n",
      "2025-12-03 00:57:48,754 - ERROR - rag_system.common - Error generating embedding: Server disconnected without sending a response.\n",
      "2025-12-03 00:57:48,754 - INFO - rag_system.common - Error in hierarchical retrieval: Server disconnected without sending a response.\n",
      "2025-12-03 00:57:48,754 - INFO - rag_system.common - Re-invoking LLM to process manual retrieval results...\n",
      "2025-12-03 00:57:48,756 - INFO - openai._base_client - Retrying request to /chat/completions in 0.435414 seconds\n",
      "2025-12-03 00:57:49,193 - INFO - openai._base_client - Retrying request to /chat/completions in 0.790625 seconds\n",
      "2025-12-03 00:57:49,985 - INFO - rag_system.common - Manual retrieval failed: Connection error.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "檢索時發生錯誤: Server disconnected without sending a response.\n"
     ]
    }
   ],
   "source": [
    "question = \"懲罰法適用對象\"\n",
    "result_state = run_query(question, config, llm=llm)\n",
    "print(result_state.get(\"generation\", \"尚未產生答案\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4378b906-2e06-4778-8bff-863f8d736034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 00:57:49,989 - INFO - rag_system.common - Using hierarchical retrieval system\n",
      "/home/jovyan/work/rag_system/common.py:76: UserWarning: SSL verification is disabled. This is insecure and should only be used for development.\n",
      "  warnings.warn(\n",
      "2025-12-03 00:57:50,004 - INFO - rag_system.common - Running workflow for question: 修法後的懲罰種類有哪些\n",
      "2025-12-03 00:57:50,004 - INFO - rag_system.common - --- GENERAL AGENT NODE ---\n",
      "2025-12-03 00:57:50,006 - INFO - openai._base_client - Retrying request to /chat/completions in 0.395577 seconds\n",
      "2025-12-03 00:57:50,403 - INFO - openai._base_client - Retrying request to /chat/completions in 0.829878 seconds\n",
      "2025-12-03 00:57:51,234 - INFO - rag_system.common - ERROR in agent_node: 處理問題時發生錯誤: Connection error.\n",
      "2025-12-03 00:57:51,243 - INFO - rag_system.common - Traceback: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "        pool_request.request\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_backends/sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/_base_client.py\", line 982, in request\n",
      "    response = self._client.send(\n",
      "        request,\n",
      "        stream=stream or self._should_stream_response_body(request=request),\n",
      "        **kwargs,\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "        request,\n",
      "    ...<2 lines>...\n",
      "        history=[],\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "        request,\n",
      "        follow_redirects=follow_redirects,\n",
      "        history=history,\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/conda/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/work/rag_system/node.py\", line 188, in agent_node\n",
      "    result = agent_executor.invoke({\n",
      "        \"messages\": messages_input\n",
      "    })\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3068, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2643, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 167, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 656, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 393, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 668, in call_model\n",
      "    response = cast(AIMessage, static_model.invoke(model_input, config))  # type: ignore[union-attr]\n",
      "                               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3129, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 398, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1117, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 927, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1221, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1356, in _generate\n",
      "    raise e\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1351, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<47 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/_base_client.py\", line 1014, in request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "During task with name 'agent' and id '67a4e84f-6c8a-8d8f-1032-f44ca0c9395f'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抱歉，處理問題時發生錯誤: Connection error.\n"
     ]
    }
   ],
   "source": [
    "question = \"修法後的懲罰種類有哪些\"\n",
    "result_state = run_query(question, config, llm=llm)\n",
    "print(result_state.get(\"generation\", \"尚未產生答案\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cdfb6b7-d069-470c-90d3-eb38ea397ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 00:57:51,247 - INFO - rag_system.common - Using hierarchical retrieval system\n",
      "/home/jovyan/work/rag_system/common.py:76: UserWarning: SSL verification is disabled. This is insecure and should only be used for development.\n",
      "  warnings.warn(\n",
      "2025-12-03 00:57:51,260 - INFO - rag_system.common - Running workflow for question: 懲罰權可以行使的期限為何？\n",
      "2025-12-03 00:57:51,261 - INFO - rag_system.common - --- GENERAL AGENT NODE ---\n",
      "2025-12-03 00:57:51,263 - INFO - openai._base_client - Retrying request to /chat/completions in 0.472865 seconds\n",
      "2025-12-03 00:57:51,736 - INFO - openai._base_client - Retrying request to /chat/completions in 0.769702 seconds\n",
      "2025-12-03 00:57:52,508 - INFO - rag_system.common - ERROR in agent_node: 處理問題時發生錯誤: Connection error.\n",
      "2025-12-03 00:57:52,510 - INFO - rag_system.common - Traceback: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "        pool_request.request\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_backends/sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/_base_client.py\", line 982, in request\n",
      "    response = self._client.send(\n",
      "        request,\n",
      "        stream=stream or self._should_stream_response_body(request=request),\n",
      "        **kwargs,\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "        request,\n",
      "    ...<2 lines>...\n",
      "        history=[],\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "        request,\n",
      "        follow_redirects=follow_redirects,\n",
      "        history=history,\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/conda/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 111] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/work/rag_system/node.py\", line 188, in agent_node\n",
      "    result = agent_executor.invoke({\n",
      "        \"messages\": messages_input\n",
      "    })\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3068, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2643, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 167, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 656, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 393, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langgraph/prebuilt/chat_agent_executor.py\", line 668, in call_model\n",
      "    response = cast(AIMessage, static_model.invoke(model_input, config))  # type: ignore[union-attr]\n",
      "                               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 3129, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/runnables/base.py\", line 5534, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 398, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1117, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 927, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 1221, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1356, in _generate\n",
      "    raise e\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 1351, in _generate\n",
      "    raw_response = self.client.with_raw_response.create(**payload)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1189, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<47 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.13/site-packages/openai/_base_client.py\", line 1014, in request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "During task with name 'agent' and id '2f6d48cd-37c7-46b8-7e52-af8a2a996362'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抱歉，處理問題時發生錯誤: Connection error.\n"
     ]
    }
   ],
   "source": [
    "question = \"懲罰權可以行使的期限為何？\"\n",
    "result_state = run_query(question, config, llm=llm)\n",
    "print(result_state.get(\"generation\", \"尚未產生答案\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d52af-8715-4fcc-b14d-1027845e301c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
